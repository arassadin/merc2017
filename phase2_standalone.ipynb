{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%env CUDA_VISIBLE_DEVICES=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tmp = keras.models.load_model('model_audio.h5')\n",
    "model_audio = keras.models.Model(model_tmp.input, model_tmp.get_layer('dropout_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tmp = keras.models.load_model('model_eyes.h5')\n",
    "model_eyes = keras.models.Model(model_tmp.input, model_tmp.get_layer('dropout_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tmp = keras.models.load_model('model_face.h5')\n",
    "model_face = keras.models.Model(model_tmp.input, model_tmp.get_layer('dropout_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tmp = keras.models.load_model('model_kinect.h5')\n",
    "model_kinect = keras.models.Model(model_tmp.input, model_tmp.get_layer('dropout_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(arr, mins, maxs):\n",
    "    arr = arr.astype(float)\n",
    "    for i in range(arr.shape[-1]):\n",
    "        arr[:, :, i] -= mins[i]\n",
    "        arr[:, :, i] /= maxs[i]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins_audio, maxs_audio = np.load('audio_mins.npy'), np.load('audio_maxs.npy')\n",
    "mins_kinect, maxs_kinect = np.load('kinect_mins.npy'), np.load('kinect_maxs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2114, 400, 36) (2114, 200, 6) (2114, 200, 100) (2114, 60, 27)\n"
     ]
    }
   ],
   "source": [
    "# X_train_audio = norm(np.load('X_train_audio.npy'), mins_audio, maxs_audio)\n",
    "X_val_audio = norm(np.load('X_val_audio.npy'), mins_audio, maxs_audio)\n",
    "\n",
    "# X_train_eyes = np.load('X_train_eyes.npy')\n",
    "X_val_eyes = np.load('X_val_eyes.npy')\n",
    "\n",
    "# X_train_face = np.load('X_train_face.npy')\n",
    "X_val_face = np.load('X_val_face.npy')\n",
    "\n",
    "# X_train_kinect = norm(np.load('X_train_kinect.npy'), mins_kinect, maxs_kinect)\n",
    "X_val_kinect = norm(np.load('X_val_kinect.npy'), mins_kinect, maxs_kinect)\n",
    "\n",
    "print X_val_audio.shape, X_val_eyes.shape, X_val_face.shape, X_val_kinect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2114,)\n"
     ]
    }
   ],
   "source": [
    "y_val = np.load('y_val.npy')\n",
    "\n",
    "print y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2114, 30) (2114, 12) (2114, 40) (2114, 20)\n"
     ]
    }
   ],
   "source": [
    "nn_audio_val = model_audio.predict(X_val_audio)\n",
    "nn_eyes_val = model_eyes.predict(X_val_eyes)\n",
    "nn_face_val = model_face.predict(X_val_face)\n",
    "nn_kinect_val = model_kinect.predict(X_val_kinect)\n",
    "\n",
    "print nn_audio_val.shape, nn_eyes_val.shape, nn_face_val.shape, nn_kinect_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_audio = RandomForestClassifier(n_estimators=100)\n",
    "predictor_eyes = RandomForestClassifier(n_estimators=100)\n",
    "predictor_face = RandomForestClassifier(n_estimators=100)\n",
    "predictor_kinect = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio: [ 0.44256121  0.40377358  0.38636364  0.42857143] 0.415317463778\n",
      "eyes: [ 0.39171375  0.29433962  0.26325758  0.26095238] 0.302565831749\n",
      "face: [ 0.58380414  0.45283019  0.60037879  0.6       ] 0.559253279921\n",
      "kinect: [ 0.44256121  0.27735849  0.33712121  0.41904762] 0.369022131752\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(predictor_audio, nn_audio_val, y_val, cv=4)\n",
    "print 'audio:', scores, np.mean(scores)\n",
    "scores = cross_val_score(predictor_eyes, nn_eyes_val, y_val, cv=4)\n",
    "print 'eyes:', scores, np.mean(scores)\n",
    "scores = cross_val_score(predictor_face, nn_face_val, y_val, cv=4)\n",
    "print 'face:', scores, np.mean(scores)\n",
    "scores = cross_val_score(predictor_kinect, nn_kinect_val, y_val, cv=4)\n",
    "print 'kinect:', scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2114, 6) (2114, 6) (2114, 6) (2114, 6)\n"
     ]
    }
   ],
   "source": [
    "weak_audio_val = cross_val_predict(predictor_audio, nn_audio_val, y_val, cv=4, method='predict_proba')\n",
    "weak_eyes_val = cross_val_predict(predictor_eyes, nn_eyes_val, y_val, cv=4, method='predict_proba')\n",
    "weak_face_val = cross_val_predict(predictor_face, nn_face_val, y_val, cv=4, method='predict_proba')\n",
    "weak_kinect_val = cross_val_predict(predictor_kinect, nn_kinect_val, y_val, cv=4, method='predict_proba')\n",
    "\n",
    "print weak_audio_val.shape, weak_eyes_val.shape, weak_face_val.shape, weak_kinect_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_weak = [0.42, 0.3, 0.56, 0.37]\n",
    "\n",
    "# preds_weak = 0.42 * weak_audio_val + 0.3 * weak_eyes_val + 0.56 * weak_face_val + 0.37 * weak_kinect_val\n",
    "preds_weak = weak_audio_val + weak_eyes_val + weak_face_val + weak_kinect_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2114,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(preds_weak, axis=1)\n",
    "\n",
    "print y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.450331125828\n"
     ]
    }
   ],
   "source": [
    "print np.mean(y_pred != y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2114, 102)\n"
     ]
    }
   ],
   "source": [
    "nn_val = np.concatenate([nn_audio_val, nn_eyes_val, nn_face_val, nn_kinect_val], axis=1)\n",
    "\n",
    "print nn_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   6.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.1s\n",
      "[ 0.61189802  0.56028369  0.66571835] 0.612633351623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   18.4s finished\n"
     ]
    }
   ],
   "source": [
    "predictor = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "scores = cross_val_score(predictor, nn_val, y_val, cv=3, verbose=2)\n",
    "print scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
